\section{Monte Carlo approach to fitting data}
% Generally propagating uncertainty such that the result of the fit contains
% Information on possible outcomes of a fit.
Something I think we should highlight:
\begin{itemize}
    \item We assume that our parameterisation is sufficiently flexible that
    the bias really does tend to 0 in infinite data limit. This is whether
    or not our likelihood is actually valid. Does the true PDF live inside
    our parameter space, or at least a good enough approximation.
    \item This is *not* the case i.e with linear model fitting quadratic law
    (we break the likelihood then bias / variance doesn't equal 1)
    \item E in and E out converge with enough data. I think we can show this
    in the polynomial model
    \item Closure test bakes in this assumption in 4.0 because we take underlying
    law from the space of functions we explore in a fit. Obviously we could use
    other underlying law but we are somewhat limited by the fact that we have the
    most flexible parameterisation.
    \item we also bake in that the shift is consistent with the uncertainty
    *and* the input function (no MHOU). Again the likelihood function is correct.
    \item In that case do we get faithful uncertainties in space of data?
    Evidence of posterior distribution of model parameters.
    \item One weakness is it's hard to get good statistics even with improved
    fitting performance, so we relax slightly this requirement
    \item Finally can check performance. If you think that the first requirement
    is satisfied (bias equals variance) then since variance $\equiv {\rm phi}^2$ and can be
    calculated for real fit then you can actually choose fit with smallest phi.
    One could wonder if we should perform hyperopt on closure data - I don't think
    so because from poly model we see that we would probably find the smallest
    architecture which fulfills assumption 1 in this list if we were to minimise
    bias (with fixed Ndata) however we *can* hyperopt with like 5-10 rep fits
    and minimise Erep[chi2](out of sample) (because noise cross term goes to zero
    and shift cross term goes down with Ndata so we really minimise bias and variance)
\end{itemize}
The next section I think should be assumptions of the data, which is consistent
throughout. Then we can talk about what is minimised in the fit. Possibly
introduce the vector notation.

\section{Fitted data}
If we consider experimental data which we assume
to be multigaussian then the experimental central values,
$\vv{\levone}$, are given by
\begin{equation}\label{eq:levelonedata}
    \vv{\levone} = \vv{\law} + \vv{\shift},
\end{equation}
where the vector of experimental values have been shifted away from
the true values given by nature, $\vv{\law}$, by a vector of shifts,
$\vv{\shift}$. The vector of shifts
is drawn from
the multigaussian, $\vv{\shift} \sim \mathcal{N}(0, \cov)$ where $\cov$ is the
experimental covariance matrix. Equation \eqref{eq:levelonedata} does not specify
a basis, but it is typical to consider $\vv{\levone}$ in the basis we call the
data basis, where basis vector corresponds to a data point, and the vector of
shifts $\vv{\shift}$ permits correlations between data points.
Equation \eqref{eq:levelonedata} is our interpretation of the
experimental data, can often be provided in different formats, such as central
values and a breakdown of systematic uncertainties. Our assumptions about the data
{\em and} the true underlying values, $\vv{\law}$,
are reflected in the posterior distribution, Eq.~(\ref{eq:PosteriorModel}).
% we never talk about normalisation uncertainties - should we? Maybe later..

Instead of simply providing the most likely model given the data, which is
the result of performing a MAP fit described in \ref{sec:inverse-problems},
we take a Monte Carlo (MC) approach to solving the inverse problem. Instead
of fitting the data, $\levone$, directly model replicas are fitted to
pseudo-data replicas. The fitted pseudo-data is generated according by
augmenting the data with some noise, $\noise^{\repind}$,
\begin{equation}\label{eq:leveltwodata1}
    \vv{\levtwo}(\vv{\law},\,\vv{\shift},\,\vv{\noise}^{\repind})
    = \vv{\law} + \vv{\shift} + \vv{\noise}^{\repind},
\end{equation}
where the replica index $k$ refers to each replica having a noise vector drawn
independently from $\vv{\noise} \sim \mathcal{N}(0, \cov)$.

The parameters for each model replica are the result of maximising the
likelihood function of the corresponding pseudo-data replicas. Qualitatively,
we often refer to propagating the data uncertainty into the space of functions.
More precisely we propagate the data uncertainty into the space of model
parameters. In more formal language, we claim that the objective of this
approach is to obtain a sample of model parameters from the posterior distribution
of the parameters given the data. Whilst it's not immediately obvious that our
MC methodology, maximising the likelihood on an ensemble of pseudo-data replicas,
should guarantee that the model replicas are indeed sampled from the posterior
distribution of parameters given data we will show that our methodology is valid
in the case that the predictions are linear in the model parameters. Then
we will provide some practical estimators in the space of data which
provide evidence, even for non-linear models, that the model uncertainties
are faithful. We present these estimators in the context of the NNPDF closure
test and will conclude with some discussions of the limitations of these estimators
and some potential directions for future work.

\section{Fitting the model parameters}

% need consistent notation with inverse section.
Each model replica has a set of parameters $\{\theta^{\repind} \}$, the theoretical
prediction from model replica $k$ for datapoint $i$ is
$\model_{i}(\{\theta^{\repind} \})$, where we have made it explicit that the observable
values calculated from the model depend on the parameters, and the values of the
parameters are distinct for each model replica. In order to determine the values
which $\theta^{\repind}$ should take, we maximise the likelihood of the parameters
given the data. The data which model replica $k$ "sees" is the corresponding
pseudodata $\vv{\levtwo}^{\repind}$ and so the likelihood of the parameters given
that data is
\begin{equation}
    \likelihood(\theta^{\repind} \vert \levtwo^{\repind}) = p(\levtwo^{\repind} | \theta^{\repind})
\end{equation}
where $\likelihood$ is the likelihood function, which is equal to the probability
density function, $p$, at fixed value $\levtwo^{\repind}$ given
$\theta^{\repind}$. Given our assumption of how $\levtwo^{\repind}$ was obtained
with two independent shifts drawn from the same multivariate gaussian
$\mathcal{N}(0, \cov)$, the probability density function at
$\levtwo^{\repind}$ is, up to normalisation,
\begin{equation}
    p(\levtwo^{\repind} | \theta^{\repind}) \sim
    \exp \left( - \frac{1}{2} \sum_{ij} \diffreptwo_i {(2\cov)}^{-1}_{ij} \diffreptwo_j \right)
\end{equation}
which is the standard expression for a multigaussian with vector of means
$\model(\theta^{\repind})$ and covariance $2C$, the covariance is $2C$ because
when summing two independent multivariate variables of the same dimension, the
sum is still normal with means and covariances summed. In other words we could
rewrite \eqref{eq:leveltwodata1} as
\begin{equation}
    \vv{\levtwo}(\vv{\law},\,\vv{\shift},\,\vv{\noise}^{\repind}\vv{\shift},\,\vv{\noise}^{\repind})
\end{equation}
where $\vv{\delta}$ is drawn from the multigaussian $\mathcal{N}(0, 2\cov)$.
It's clear that the mean and covariance
across replicas of $\levtwo^{\repind}$, with fixed $\shift$ are
$\levone$ and $\cov$ respectively. This seems slightly counter intuitive because
$\vv{\shift}$ is fixed and unknown to us and when performing a fit we effectively
bootstrap over $\vv{\noise}^{\repind}$ however,
when fitting a single replica we should imagine that
we do not know the exact value of $\noise^{\repind}$ and disregard the fact
that we are fitting other replicas and simply try to find the set of parameters
$\model(\theta^{\repind})$ which maximises the likelihood of giving that data
when $\delta ~ \mathcal{N}(0, 2\cov)$ is applied. In a fit to real experimental
data we are unable to
bootstrap over $\vv{\shift}$ because the experimental central values are fixed
to the value which are published, however in the closure tests we present later
we will use a pre-existing PDF to produce observable values for the underlying
law $\vv{\law}$ and generate $\vv{\shift}$ self consistent with our assumptions
about the distribution it is drawn from, in which case we can perform tests on
our methodology that take into account that $\vv{\shift}$ is a stochastic
variable.

In practice we actually maximise the log-likelihood,
\begin{equation}
    \logll(\theta^{\repind} \vert \levtwo^{\repind}) = \ln \left[
        \likelihood(\theta^{\repind} \vert \levtwo^{\repind}) \right],
\end{equation}
because $\ln$ is a monotonic function, so $\logll$ has a maximum at the same value
of $\theta^{\repind}$. Furthermore, maximising the log-likelihood is the same
as minimising the $\chi^2$ between $\levtwo(\noise^{\repind}, \shift, \law)$
and $\model(\theta^{\repind})$ defined as
\begin{equation}
    \chi^2(\model(\theta^{\repind}) \vert \levtwo(\noise^{\repind}, \shift, \law))
    = \sum_{ij} \diffreptwo_i {(2\cov)}^{-1}_{ij} \diffreptwo_j.
\end{equation}
To be very precise, since
we are interested in finding the minimimum with respespected to the parameters,
or the point at which
$\frac{\partial}{\partial \theta^{\repind}}
\chi^2(\model(\theta^{\repind})\vert \levtwo(\noise^{\repind}, \shift, \law)) = 0$
it doesn't matter in reality whether we minimise
$\chi^2(\model(\theta^{\repind})\vert \levtwo(\noise^{\repind}, \shift, \law))$ or
any scalar multiple of that. Also, since ${(2\cov)}^{-1} = \frac{1}{2}\invcov{}$
then we actually minimise
\begin{equation}\label{eq:replicalossindex}
    \repchis = \frac{1}{\ndata} \sum_{ij} \diffreptwo_i \invcov{ij} \diffreptwo_j.
\end{equation}
The parameters obtained from minimising this function are the parameters which
maximise the likelihood of
$\likelihood(\theta^{\repind} \vert \levtwo^{\repind})$. Finally, as a matter
of convenience we can rewrite equation \eqref{eq:replicalossindex} as a matrix
product
\begin{equation}\label{eq:replicaloss}
    \repchis = \frac{1}{\ndata} {\vecdiffreptwo}^{T} \invcov{} \vecdiffreptwo
\end{equation}
where $\vecdiffreptwo$, is a column vector.

\subsection{Closure test}

In a closure test, instead of assuming that the experimental central values are
statistically consistent with an underlying law, as in \eqref{eq:levelonedata},
we use a pre-existing function to generate predictions which we treat as the
underlying law, $\vv{\law}$. We then generate the experimental
central value, by drawing the vector of shifts consistently with our assumption
that $\vv{\shift} \sim \mathcal{N}(0, \cov)$. We refer to predictions obtained
from the input function, $\vv{\law}$, as level 0 data. This are the true values
which we are aiming to reproduce with our models when fitting the pseudodata.
The generated
experimental central values, $\vv{\levone}$, are referred to as level 1 data.
Finally the pseudodata replicas are generated from the $\levone$ data,
analogously to a fit to experimental data. We refer to the pseudodata replicas,
$\vv{\levtwo}$, as level 2 data.
% This needs rewording but emphasise that there are two assumptions which we enforce.

% Get rid of the stuff below.
Whilst the parameters of the model replicas are determined by minimising
the loss function given by equation \eqref{eq:replicaloss}, the overall fit
quality is determined by considering the $\chi^2$ between the experimental
central values and the expectation value of the theory predictions
\begin{equation}\label{eq:centralchi2}
    \chi^2 = \frac{1}{\ndata} {\vecdiffcentone}^{T} \invcov{} \vecdiffcentone,
\end{equation}
where $\erep{\cdot}$ denotes the mean value across replicas, so $\erep{g}$ is
the mean of the theory predictions across replicas. This $\chi^2$ is a measure
of the difference between the expectation value of the prediction and the
experimental central values in units of the covariance. This function is clearly
related to the probability of getting the experimental central values, given
the central model predictions, $p(\levone \vert \erep{\model})$ in anaology to
how the log-likelihood, $\logll$, is related to $p(\levtwo \vert \model)$. In
the limit of infinte data we expect $\chi^2 \rightarrow 1$. In a fit to
experimental data we are limited to assessing the performance of a fit
using this quantity because we don't have knowledge of the underlying
theory predictions, $\vv{\law}$. What's more, we are relying on a number of 
assumptions such as the experimental central values being distributed
according self consistently as a multigaussian centered on the underlying law
with covaraince given by the experimental covariance matrix. The aim of the
closure test is to be able to determine that if our assumptions are true, then
does the methodology at least pass some criteria in the ideal case. Determining
whether this conclusions from the closure test hold with real world data is
outside of the scope of this paper, and essentially a large part of the discussion
in the main NNPDF papers. Criteria which we want to be able to test with the closure
test are: Whether the distribution of replicas for each fit is
consistent with the distribution of fits about the underlying law, and
whether the methodology avoids overfitting the fluctuations in the data. One we are
confident that a methodology satisfies both of those criteria, we would also
like to have some performance indicators which tell us out of a number of proposed
candidate methodologies which produces the best results. Some statistical
estimators will be presented which aim to answer these questions and then the
estimators will be discussed within the context of several models. Finally we
will look at the feasibility and usefulness of these statistical estimators in
the context of fitting parton distributions with neural networks within the
NNPDF framework.
