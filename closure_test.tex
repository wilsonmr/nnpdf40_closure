\section{NNPDF Monte Carlo approach to inverse problems}
\label{sec:closure-test}

In this section we discuss the NNPDF approach to inverse problems, trying to
make contact explicitly with the formalism laid out in
Sec.~\ref{sec:inverse-problems}. In particular, Eq.~\eqref{eq:PosteriorModel}
gives a formal description of propagating the information contained in the
experimental data into model space. In practice, sampling from the posterior
distribution is not straightforward and we defer the investigation of this issue
to further studies. 

\subsection{Fitting replicas}
\label{sec:fit-reps}

The approach for generating a sample in model space employed by NNPDF can
broadly be described as fitting model replicas to pseudo-data replicas. As
discussed in Eq.~\eqref{eq:NoisyInverseProblem} the experimental values are
subject to observational noise. If we assume this observational noise to be
multigaussian then the experimental central values, $\obspriorcent$, are given
explicitly by
\begin{equation}
    \label{eq:levelonedata}
    \obspriorcent = \law + \obsnoise,
\end{equation}
where $\law$ is the vector of {\em true} observable values, and the obervational
noise is drawn from a Gaussian centered on zero such as in
Eq.~\ref{eq:RhoGauss}, \ie\ $\obsnoise \sim \mathcal{N}(0, \obspriorcov)$ where
$\obspriorcov$ is the experimental covariance matrix. In
Eq.~\eqref{eq:levelonedata}, each basis vector corresponds to a separate data
point, and the vector of shifts $\obsnoise$ permits correlations between data
points according to the covariance matrix provided by the experiments. Given the
data, the NNPDF approach is to compute a MAP estimator similar to that discussed
in the previous section, \ie\ finding the model that minimises the $\chi^2$ to
the data. The key difference between the NNPDF approach and the classical MAP
estimator is that instead of fitting the observational data given by
Eq.~\ref{eq:levelonedata}, an ensemble of model replicas are fitted each to an
independently sampled instance of pseudo-data, which is generated by augmenting
$\obspriorcent$ with some noise, $\noise^{\repind}$,
\begin{equation}
    \label{eq:leveltwodata1}
    \pseudodat^{\repind} = \obspriorcent + \noise^{\repind}
    = \law + \obsnoise + \noise^{\repind},
\end{equation}
where $k$ is the replica index and each instance of the noise, $\noise$, is
drawn independently from the same Gaussian from which the observational noise is
drawn from, \ie\ $\noise \sim \mathcal{N}(0, \obspriorcov)$. A simple
one-dimensional example is shown in Fig.~\ref{fig:DistRep}. Note that, if we
were to repeat this construction multiple times, the true value $f$ would be
within a 1$\sigma$ interval centred at $y_0$ with a 68\% probability.
\begin{figure}
    \centering
    \includegraphics[scale=0.6]{ReplicaDistribution.png}
    \caption{Histogram showing the distribution of $10^4$ replicas generated around an experimental value $y_0$ with unit variance. The central value $y_0$, which is represented by the solid dot at the centre of the replica distribution, is drawn from a Gaussian distribution with unit variance centred at the true value $f$, which is assumed to be the origin in this plot.\label{fig:DistRep}}
\end{figure}

The parameters for each model replica maximise the likelihood evaluated on the
corresponding pseudo-data. We can think of this approach as a special case of
MAP estimation, as described in Eq.~\eqref{eq:MAP}, where there is no model
prior that regulates the likelihood. Another way of viewing this is to take
$\modelpriorcov^{-1} \to 0$ in Eq.~\eqref{eq:MAP}, as was done to obtain the
result in Eq.~\ref{eq:NoPriorLinModel}. Either way, there is no prior
information about the model. The parameterisation of the model is fixed, so the
model space is the finite space of parameters $\modelvec \in \real^{\nmodel}$.
In $\real^{\nmodel}$, we find the parameters which minimise the $\chi^2$ between
the predictions from the model and the corresponding pseudo-data
$\pseudodat^{\repind}$
\begin{equation}\label{eq:NNPDFLikelihood}
    \begin{split}
        \modelvecrep &= \arg\min_{\modelvec^{\repind}} \repchis \\
        &= \arg\min_{\modelvec^{\repind}} \sum_{ij}
        \left( \fwdobsop(\modelvec^{\repind}) - \pseudodat^{\repind} \right)^T
        \obspriorcov^{-1}
        \left( \fwdobsop(\modelvec^{\repind}) - \pseudodat^{\repind} \right) \, ,
    \end{split}
\end{equation}
where, as usual, minimising the $\chi^2$ is equivalent to maximising the
likelihood, $\likelihood$, since $\chi^2 \equiv -\log{\likelihood}$.
% The uncertainty on the MAP estimator is computed by bootstrapping the
% data, \ie\ by generating an ensemble of pseudo-data, called replicas, that
% fluctuate around $\obspriorcent$. By fitting each replica, we obtain an ensemble
% of models whose distribution is representative of the fluctuations of the MAP
% estimator. The fitted pseudo-data is generated by augmenting the data with some
% noise, $\noise^{\repind}$,

As a final note: since we do not include the model prior, overall normalisations
can be omitted in Eq.~\ref{eq:NNPDFLikelihood}. It is clear however that if we
were including a model prior in our MAP, it is important that the relative
normalisations between the likelihood function and the model prior are
self-consistent.

\subsection{Fluctuations of fitted values}
\label{sec:fluct-fit-values}

It is not immediately obvious that our MC methodology, maximising the likelihood
on an ensemble of pseudo-data replicas, should guarantee that the model replicas
are indeed sampled from the posterior distribution of parameters given data as
described \eg\ in Eq.~\ref{eq:PosteriorModel}. In order to investigate this
issue, we will again consider a model, whose predictions are linear in the model
parameters, where the posterior distribution of model parameters can be written
explicitly. A practical example, which can
elucidate the following arguments would be a polynomial model. Then $\modelvec$ is a
vector of $\nmodel$ polynomial coefficients and $\linmap$ is the Vandermonde matrix
\begin{equation}
    \linmap =
    \begin{bmatrix}
        1  & x_1 & \ldots& x_1^{\nmodel-1} \\ 
        1  & x_2 & \ldots& x_2^{\nmodel-1} \\ 
        \vdots  & \vdots & \vdots& \vdots \\ 
        1  & x_{\ndata} & \ldots & x_{\ndata}^{\nmodel-1} 
    \end{bmatrix}.
\end{equation}
In this case the forward map yields
\begin{equation}
    \label{eq:PolyMod}
    y_i = \sum_{j=0}^{\nmodel-1} u_j x_i^j\, , 
\end{equation}
where $i=1,\ldots,\ndata$. The arguments here are not restricted to polynomials,
however, and apply to any model whose forward map can be expressed as
Eq.~\eqref{eq:MatrixG}, for example a linear shallow approximation of neural
networks \cite{ADVANI2020428}. In order to get an exact analytical solution for
the linear model, we additionally require $\linmap$ to have linearly independent
rows, and therefore $\linmap \obspriorcov \linmap^T$ is invertible. With no
prior information on the model, the posterior distribution of model parameters
is a Gaussian with mean and covariance given by Eqs.~\ref{eq:NoPriorLinModel}
and \ref{eq:NoPriorLinModelCov}.

If instead we deploy the NNPDF Monte Carlo method to fitting model replicas,
then in the case under study $\arg\min_{\modelvec^{\repind}} \repchis$ is found
analytically by imposing thatthe derivative of $\repchis$ with respect to the
model parameters is zero, i.e.
\begin{equation}
    \begin{split}
        \label{eq:MAPEstLinModel}
        \modelvecrep &= (\linmap^T \obspriorcov^{-1} \linmap)^{-1}
        \left(
            \linmap^T \obspriorcov^{-1} \obspriorcent +
            \linmap^T \obspriorcov^{-1} \noise^{\repind}
        \right) \, .
    \end{split}
\end{equation}
Eq.~\ref{eq:MAPEstLinModel} shows that $\modelvec_*$ is a linear
combination of the Gaussian variables $\noise$, and therefore is
also a Gaussian variable. Its
probability density is then completely specified by the average and
covariance of $\modelvec_*$, which can be calculated explicitly, given that the
probability density for $\noise$ is known:
\begin{align}
    \emodel{\modelvec_*} &=
    \modelpostcent = (\linmap^T \obspriorcov^{-1} \linmap)^{-1} \linmap^T
    \obspriorcov^{-1} \obspriorcent \\
    {\rm cov}(\modelvec_*) &= \modelpostcov = (\linmap^T \obspriorcov^{-1} \linmap)^{-1} \, .
\end{align}
We see explicitly here that, under the assumptions specified above, $\modelvec_*
\sim \mathcal{N}(\modelpostcent, \, \modelpostcov)$. In other words, when the
model predictions are linear in the model parameters, the NNPDF MC method is
shown to produce a sample of models from the posterior distribution of model
parameters given the data. When we fit PDFs, parameterised as deep fully
connected neural networks, to data which includes hadronic observables, it is
clear that the forward map is non-linear, and therefore this proof does not
strictly apply. As previously discussed at the end of Sec.~\ref{sec:LinProbs},
even for non-linear models we can make a linear approximation of the forward map
provided that we are expanding around the MAP estimator. This means the NNPDF MC
methodology should reproduce the posterior distribution of the model given the
data, at least close $\modelpostcent$, the central value of the fitted replicas.
Furthermore, by fluctuating the data and fitting the replicas, the fluctuations
in data space are propagated to model space non-linearly. So even for non-linear
problems, the NNPDF MC methodology will produce a sample of models which are at
least approximately distributed according to the posterior model distribution,
and it may be that further away from the MAP estimator the approximation holds
well due to the non-linear dependence of the model replicas on the data
uncertainities. {\bf need to make the last sentence more explicit}

\subsection{Closure test}
\label{sec:closure-test-intro}

The concept of the closure test, which was first introduced in
Ref.~\cite{nnpdf30}, is to construct artificial data by using a known
pre-existing function to generate the {\em true} observable values, $\law$. One
way of achieving this is by choosing $\lawmodel$ such that $\law =
\fwdobsop(\lawmodel)$. Then the experimental central values are artificially
generated according to Eq.~\ref{eq:levelonedata}, where the observational noise
is pseudo-randomly generated from the assumed distribution.

In \cite{nnpdf30}, $\law$ is referred to as level 0 (L0) data and
$\obspriorcent$ is referred to as level 1 (L1) data. Finally, if we use the
NNPDF MC method to fit artificially generated closure data, the pseudo-data
replicas that are fitted by the model replicas are referred to as level 2 (L2)
data.

In a closure test, the assumed prior of the data is fully consistent with the
particular instance of observed central values, $\obspriorcent$, by construction.
In the original closure test in NNDPF3.0 there was also no
modelisation uncertainty, the true observable values were assumed to be obtained
by applying the forward map $\fwdobsop$ to a vector in model space $\lawmodel$.
It is worth noting that the assumption of zero modelisation uncertainties is
quite strong and likely unjustified in many areas of physics. In the context of
fitting parton distribution functions there are potentially missing higher order
uncertainties (MHOUs) from using fixed order perturbative calculations as part
of the forward map. MHOUs have been included in parton distribution fits
\cite{AbdulKhalek:2019ihb} and in the future these should be included in the
closure test, however this is beyond the scope of the study presented here,
since MHOUs are still not included in the NNPDF methodology by default. In the
results presented in the rest of this paper we do include nuclear and deuteron
uncertainties, as presented in \cite{Ball:2018twp, Ball:2020xqw}, since they are
to be included in NNPDF fits by default. Extensive details for including
theoretical uncertainties, modelled as theoretical covariance matrices can be
found in those references. For the purpose of this study the modelisation
uncertainty is absorbed into the prior of the data, since
\begin{equation}
    \obspriorcent = \fwdobsop(\modelvec) + \obsnoise + \delta
\end{equation}
where $\delta \sim \mathcal{N}(0, \cov^{\rm theory})$. As long as the
modelisation uncertainty is independent of the data uncertainty, we can absorb
$\delta$ into $\obsnoise$ by modifying the data prior: $\obsnoise \sim
\mathcal{N}(0, C + C^{\rm theory})$. In doing that, we must also update the
likelihood of the data given the model to use the total covariance $(C + C^{\rm
theory})$. From now onwards we will omit $C^{\rm theory}$ because it is implicit
that we always sample and fit data using the total covariance matrix which
includes any modelisation uncertainty we currently take into account as part of
our methodology.

Mapping the closure test procedure to the quantities used in the Bayesian
treatment presented in the previous section will allow us to derive a number of
analytical results in Sect.~\ref{Sec:LinearMapEstimators}.