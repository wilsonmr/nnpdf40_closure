\section{Estimators}
Since we have access to the underlying predictions in a closure test we can
define some new estimators which can be used to determine how well a fit
performs.

We start with the expectation of $\repchis$ across replicas
\begin{equation}
    \label{eq:chi2kerep}
    \erep{\repchis} = \frac{1}{\ndata} 
    \erep{ \sum_{ij} \diffreptwo_i \invcov{ij} \diffreptwo_j}.
\end{equation}
This can be decomposed, by completing the square, into 4 terms
\begin{equation}
    \label{eq:chi2decomp}
    \begin{split}
        \erep{\repchis} &= {\rm noise} + {\rm bias} + {\rm variance} - {\rm cross\,term} \\
        &=  {\rm noise} + {\rm variance} + \Delta_{\chi^2}, \\
        &= \chi^2 + {\rm variance}
    \end{split}
\end{equation}
where $\Delta_{\chi^2}$ is an estimator that has been discussed in previous
NNPDF closure test studies, and $\chi^2$ was defined in eq.
\eqref{eq:centralchi2}.

\subsection{Bias}

The {\em bias}\ is defined as the difference between the central value of the
replica predictions and the predictions obtained from the underlying law in
units of the covariance, \ie 
\begin{equation}
    \label{eq:BiasDef}
    \bias = \frac{1}{\ndata} \sum_{ij} \diffcentunder_i \invcov{ij} \diffcentunder_j.
\end{equation}
It is desirable for a fit to have a smaller bias because that indicates
that the fit is reproducing the underlying predictions well.

\subsection{Variance}

The {\em variance} in the above decomposition refers to the variance of the
replica predictions in units of the covariance
\begin{equation}
    \label{eq:VarDef}
    \var = \frac{1}{\ndata} \erep{ \sum_{ij} \diffcentrep_{i} \invcov{ij} \diffcentrep_{j}},
\end{equation}
which can be interpreted as the propagation of the PDF uncertainty in the space
of data. It is important to note that both variance and bias can be determined
purely from the ensemble of PDF replicas and the underlying law.

\subsection{Multiple Closure Fits}

As well as being able to calculate the bias estimator in a closure test and see
how well the underlying law is reproduced, an advantage to testing the
methodology with closure tests is the ability to generate ensembles of level one
data - or experimental central values.

Performing multiple closure fits on
different configurations of level one shifts facilitates testing whether or not
the distribution of replica predictions about their mean for a given closure fit
is representative of the distribution of central values of the
predictions for different closure fits about the underlying law. This is ultimately
a test of whether the uncertainties provided with a single fit are
representative.

\subsection{Bias Variance ratio}

If we were to perform multiple fits with different level-1
shifts and calculate the expectation value of the bias across fits,
$\eshift{\bias}$, then we can calculate
\begin{equation}
    \label{eq:BiasVarRatio}
    \frac{\eshift{\bias}}{\var} = 1.
\end{equation}
There is a clear geometric interpretation of this quantity.
In the basis which diagonalises the experimental
covariance matrix the variance is the mean squared radius of the replica predictions for a
given fit and the expected bias is the mean squared radius of the central value
of the predictions. We assume that the variance has a value which is
independent of $\shift$ and, with enough replicas, is constant across fits.
In practice we will also take the expectation value of $\var$ across fits,
because we will be running fits with finite replicas and so expect fluctuations
across fits.

If we look at the functional form of $\eshift{\bias}$ then we see that it is
the same form as that of $\var$. The difference is the expectation value is
being taken over fits instead of replicas and the difference is between the
central predictions of a fit and the underlying law. We can rewrite the variance
in the basis which diagonalises the experimental covmat as
\begin{equation}
    \var = \frac{1}{\ndata} \erep{ \sum_{i} \frac{(\hat{\Delta}_{i, \noise})^2}{\hat{\sigma}_{i}^2}},
\end{equation}
where $\underline{\hat{\Delta}}$ is the vector of differences, $\diffcentrep$,
projected into the eigenbasis of the covmat and $\hat{\sigma}^2$ are the
eigenvalues of the covmat. If we take the expectation over replicas before
summing over the data points
\begin{equation}
    \var = \frac{1}{\ndata} \sum_{i} {\rm Var}(\frac{\hat{\Delta}_i}{\hat{\sigma}_i}),
\end{equation}
then we see that variance is the mean across data points of the second moment
of the distribution of replica predictions about the central value of the predictions.
A similar argument can be applied to $\eshift{\bias}$.

Then $\frac{\eshift{\bias}}{\eshift{\var}}$ is an estimate of whether the average
of the second moments of the distributions across data points is equal. This
is a rough estimate of whether the second moment of the two distributions match
which would clearly be determining if the covariance matrix of the two distributions
was equal, element by element. Having a sufficient number of fits and replicas
to be able to determine this quantity is unobtainable, even with the increased
speed of fits and so instead we opt to calculate this cruder estimate.

If the distribution of central predictions is Gaussian about the underlying law
and the distribution of replica predictions is Gaussian about the central prediction
then showing that the covariance matrix of each distribution is equal is equivalent
to showing that the K-L divergence between the two distributions is 0. In this
case it is clear that the replicas of a given fit are distributed as though
they were drawn from $p(f|{\rm data})$, in which case the uncertainties on
our predictions is faithful.

\subsubsection{Quantile statistics}

A closure test estimator which was previously defined in PDF space was
$\xi_{1\sigma}$. We define here an analogous estimator in data space
\begin{equation}
    \label{eq:XiDataDef}
    \xi_{1\sigma} = 
        \frac{1}{\ndata} \sum_{i}^{\ndata} 
        \frac{1}{\nfits} \sum_{l}^{\nfits}
            I_{[-\sigma_i^{(l)}, \sigma_i^{(l)}]}
            \left( \erep{\model_i}^{(l)} - \law_i \right),
\end{equation}
where $\sigma^{(l)}$ is the standard deviation of the theory predictions
estimated from the replicas of fit $l$. $\xi_{1\sigma}$ aims to measure the same
thing as $\frac{\eshift{\bias}}{\eshift{\var}}$: whether the distribution of
replicas for a given fit matches the distribution of the central predictions
around the underlying predictions. It is useful to define $\xi_{1\sigma}^{i}$ as
the value of $\xi_{1\sigma}$ for an individual data point such that
\begin{equation}
    \label{eq:XiDataIDel}
    \xi_{1\sigma} = \frac{1}{\ndata} \sum_i \xi_{1\sigma}^{i}.
\end{equation}
If we assume that the replica distribution is constant across fits then our
definition $\xi_{1\sigma}^{i}$ is just a discretised expectation value of the
indicator function. In the case that we have infinite fits, then
\begin{equation}
    \label{eq:XiIExpecVel}
    \xi_{1\sigma}^{i} = 
    \int_{-\infty}^{\infty} I_{[-\sigma_i, \sigma_i]}\, 
    p(\erep{\model_i} - \law_i)\, 
    {\rm d}(\erep{\model_i} - \law_i).
\end{equation}
If we then assume that $p(\erep{\model_i} - \law_i)$ is a gaussian centered on
zero with a standard deviation which we will denote as $\modelstd_i$ then the
integral simplifies to
\begin{equation}
    \label{eq:expectedxi}
    \xi_{1\sigma}^{i} = 
    \erf \left( \frac{\sigma_i}{\modelstd_i \sqrt{2}}\right),
\end{equation}
which is the standard result of integrating a gaussian over some finite
symmetric interval. Clearly if the distribution of central predictions about the
underlying law matches the distribution of the replica predicitons around the
central predictions then the expected value of $\xi_{1\sigma}^{i}$ is 0.68. This
is consistent with the assumptions we made, \viz\ it is  the quantile statistics
of a gaussian distribution.

One can also look at the variance of the indicator function across fits to get
an idea of the fluctuation of $\xi_{1\sigma}^{i}$, which we will denote as
$\Delta[\xi_{1\sigma}^{i}]$
\begin{equation}
    \label{eq:XiIVar}
    \begin{split}
        \Delta[\xi_{1\sigma}^{i}] 
        =& \int_{-\infty}^{\infty} I_{[-\sigma_i, \sigma_i]}^2\, 
            p(\erep{\model_i} - \law_i)\,
            {\rm d}(\erep{\model_i} - \law_i) - \\
        &- \left( \int_{-\infty}^{\infty} I_{[-\sigma_i, \sigma_i]}\,
            p(\erep{\model_i} - \law_i)\,
            {\rm d}(\erep{\model_i} - \law_i) \right)^2,
    \end{split}
\end{equation}
which can be simplified to
\begin{equation}
    \label{eq:XiIVarSimplified}
    \Delta[\xi_{1\sigma}^{i}] =
    \erf \left( \frac{\sigma_i}{\modelstd_i \sqrt{2}}\right) -
    \erf \left( \frac{\sigma_i}{\modelstd_i \sqrt{2}}\right)^2.
\end{equation}
Even in the ideal case that the distributions are the same, we see that the
$\Delta[\xi_{1\sigma}^{i}] = 0.22$, which is a large spread considering
$\xi_{1\sigma}^{i}$ is bounded between 0 and 1.

When taking the mean across datapoints to obtain $\xi_{1\sigma}$ we note that
getting 0.68 relies on each sampled $\xi_{1\sigma}^{i}$ being statistically
independent. This clearly will not be the case because there can be a big
correlation between datapoints within the same dataset. We can calculate
$\xi_{1\sigma}$ in different basis and note that unlike $\chi^2$ and quantities
of the form $v^T M v$, $\xi_{1\sigma}$ is not basis independent. There is a
choice of basis, however it will be useful to compare the value $\xi_{1\sigma}$
and $\frac{\eshift{\bias}}{\eshift{\var}}$. Therefore, a natural basis to
calculate $\xi_{1\sigma}$ is the basis which diagonalises the experimental
covariance matrix because bias and variance are both calculated in units of the
experimental
% Should I mention this without having tried it?
covariance. Alternatively one could estimate the covariance of the difference
between replicas and central values and then rotate the differences between
the central predictions and the underlying law into the basis which diagonalises
this replica covariance matrix.

\subsection{Out of sample}

We want to calculate the closure test estimators on data which is out of sample
to check uncertainty is faithful on predictions.

\paragraph{TODO}{Review the toy model here and show that in/out of sample
didn't make difference - {\bf LDD}}
